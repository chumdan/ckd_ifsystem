"""
PIMS ë°ì´í„° ì¡°íšŒ ì„œë¹„ìŠ¤
ì¥ê³  ë°©ì‹ì²˜ëŸ¼ ì§ì ‘ SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•´ì„œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ë“¤
"""

import pymssql
import pandas as pd
import os
from datetime import datetime
from typing import Dict, List, Any
from app.config import get_mssql_connection_dict


def load_tag_mapping() -> Dict[str, str]:
    """
    íƒœê·¸ ë§¤í•‘ CSV íŒŒì¼ì„ ì½ì–´ì„œ ì˜ë¬¸ -> í•œê¸€ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, str]: {ì˜ë¬¸ì»¬ëŸ¼ëª…: í•œê¸€ì»¬ëŸ¼ëª…} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # CSV íŒŒì¼ ê²½ë¡œ (app í´ë” ê¸°ì¤€)
        csv_path = os.path.join(os.path.dirname(__file__), '..', 'íƒœê·¸ë³€í˜•.csv')
        
        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (original_nam -> display_name)
        tag_mapping = dict(zip(df['original_nam'].str.strip(), df['display_name'].str.strip()))
        
        print(f"íƒœê·¸ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(tag_mapping)}ê°œ")
        return tag_mapping
        
    except Exception as e:
        print(f"íƒœê·¸ ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def load_process_mapping() -> Dict[str, str]:
    """
    ê³µì •ëª… ë§¤í•‘ CSV íŒŒì¼ì„ ì½ì–´ì„œ ê³µì •ì½”ë“œ -> í•œê¸€ê³µì •ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        Dict[str, str]: {ê³µì •ì½”ë“œ: í•œê¸€ê³µì •ëª…} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # CSV íŒŒì¼ ê²½ë¡œ (app í´ë” ê¸°ì¤€)
        csv_path = os.path.join(os.path.dirname(__file__), '..', 'ê³µì •name.csv')
        
        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (KTSCH -> LTXA1)
        process_mapping = dict(zip(df['KTSCH'].str.strip(), df['LTXA1'].str.strip()))
        
        print(f"ê³µì •ëª… ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(process_mapping)}ê°œ")
        return process_mapping
        
    except Exception as e:
        print(f"ê³µì •ëª… ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def filter_and_convert_processes(data: List[Dict[str, Any]], process_mapping: Dict[str, str]) -> List[Dict[str, Any]]:
    """
    ê³µì • ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê³  í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        data: ì›ë³¸ ê³µì • ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        process_mapping: ê³µì •ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
    
    Returns:
        List[Dict[str, Any]]: í•„í„°ë§ë˜ê³  í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜ëœ ê³µì • ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not data or not process_mapping:
        return data
    
    filtered_data = []
    
    for row in data:
        proc_code = row.get('KTSCH', '').strip()
        
        # ê³µì •ëª… ë§¤í•‘ì— ìˆëŠ” ê³µì •ì½”ë“œë§Œ í¬í•¨
        if proc_code in process_mapping:
            # ìƒˆë¡œìš´ í–‰ ìƒì„± (ì›ë³¸ ë°ì´í„° ë³µì‚¬)
            new_row = dict(row)
            # ê³µì •ëª…ì„ í•œê¸€ë¡œ ë³€í™˜í•´ì„œ ì¶”ê°€ (ê¸°ì¡´ KTSCHëŠ” ìœ ì§€)
            new_row['PROCESS_NAME_KOR'] = process_mapping[proc_code]
            filtered_data.append(new_row)
    
    return filtered_data


def filter_by_time_range(data: List[Dict[str, Any]], start_time: str, end_time: str, tag_mapping: Dict[str, str]) -> List[Dict[str, Any]]:
    """
    ì‹œê°„ ë²”ìœ„ë¡œ ë°ì´í„°ë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤.
    
    Args:
        data: ì›ë³¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜ëœ ìƒíƒœ)
        start_time: ì‹œì‘ ì‹œê°„ (YYYY-MM-DD HH:MM:SS í˜•íƒœ)
        end_time: ì¢…ë£Œ ì‹œê°„ (YYYY-MM-DD HH:MM:SS í˜•íƒœ)
        tag_mapping: íƒœê·¸ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ (ì‹œê°„ ì»¬ëŸ¼ëª…ì„ ì°¾ê¸° ìœ„í•´)
    
    Returns:
        List[Dict[str, Any]]: ì‹œê°„ ë²”ìœ„ë¡œ í•„í„°ë§ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not data or not start_time or not end_time:
        return data
    
    # íƒœê·¸ ë§¤í•‘ì—ì„œ 'ì‹œê°„' ì»¬ëŸ¼ëª… ì°¾ê¸° (í•œê¸€ëª…)
    time_column = None
    for eng_col, kor_col in tag_mapping.items():
        if kor_col == 'ì‹œê°„':
            time_column = kor_col
            break
    
    if not time_column:
        print("ì‹œê°„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì‹œê°„ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return data
    
    try:
        # ì‹œì‘/ì¢…ë£Œ ì‹œê°„ì„ datetime ê°ì²´ë¡œ ë³€í™˜
        # HTML datetime-local í˜•íƒœ ì²˜ë¦¬: 2024-05-23T21:04 -> 2024-05-23 21:04:00
        def parse_input_time(time_str):
            time_str = time_str.strip()
            if 'T' in time_str:
                # Të¥¼ ê³µë°±ìœ¼ë¡œ ë³€ê²½
                time_str = time_str.replace('T', ' ')
            
            # ì´ˆê°€ ì—†ìœ¼ë©´ :00 ì¶”ê°€
            if time_str.count(':') == 1:
                time_str += ':00'
            
            return datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
        
        start_dt = parse_input_time(start_time)
        end_dt = parse_input_time(end_time)
        
        filtered_data = []
        
        for row in data:
            time_value = row.get(time_column)
            if time_value:
                try:
                    # ë°ì´í„°ì˜ ì‹œê°„ ê°’ì„ datetimeìœ¼ë¡œ ë³€í™˜
                    # 2024-05-23 9:05:10 í˜•íƒœì—ì„œ ì•ì— ê³µë°±ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ strip ì²˜ë¦¬
                    time_str = str(time_value).strip()
                    
                    # ì‹œê°„ í˜•íƒœ ì •ê·œí™” (í•œ ìë¦¬ ì‹œê°„ì„ ë‘ ìë¦¬ë¡œ)
                    # "2024-05-23 9:05:10" -> "2024-05-23 09:05:10"
                    if ' ' in time_str:
                        date_part, time_part = time_str.split(' ', 1)
                        time_parts = time_part.split(':')
                        if len(time_parts) >= 3:
                            hour = time_parts[0].zfill(2)  # í•œ ìë¦¬ ì‹œê°„ì„ ë‘ ìë¦¬ë¡œ
                            minute = time_parts[1].zfill(2)
                            second = time_parts[2].zfill(2)
                            time_str = f"{date_part} {hour}:{minute}:{second}"
                    
                    row_dt = datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
                    
                    # ì‹œê°„ ë²”ìœ„ ì²´í¬
                    if start_dt <= row_dt <= end_dt:
                        filtered_data.append(row)
                        
                except ValueError as e:
                    print(f"ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜ ('{time_value}'): {e}")
                    # íŒŒì‹± ì˜¤ë¥˜ê°€ ìˆì–´ë„ í•´ë‹¹ í–‰ì€ í¬í•¨ (ì•ˆì „ì¥ì¹˜)
                    filtered_data.append(row)
        
        print(f"ì‹œê°„ í•„í„°ë§ ì™„ë£Œ: {len(data)}ê±´ -> {len(filtered_data)}ê±´")
        return filtered_data
        
    except Exception as e:
        print(f"ì‹œê°„ í•„í„°ë§ ì˜¤ë¥˜: {e}")
        return data


def convert_columns_to_korean(data: List[Dict[str, Any]], tag_mapping: Dict[str, str]) -> List[Dict[str, Any]]:
    """
    ë°ì´í„°ì˜ ì»¬ëŸ¼ëª…ì„ ì˜ë¬¸ì—ì„œ í•œê¸€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        data: ì›ë³¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        tag_mapping: íƒœê·¸ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
    
    Returns:
        List[Dict[str, Any]]: ì»¬ëŸ¼ëª…ì´ í•œê¸€ë¡œ ë³€í™˜ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not data or not tag_mapping:
        return data
    
    converted_data = []
    
    for row in data:
        converted_row = {}
        for eng_col, value in row.items():
            # íƒœê·¸ ë§¤í•‘ì—ì„œ í•œê¸€ëª… ì°¾ê¸° (ì—†ìœ¼ë©´ ì›ë³¸ ì»¬ëŸ¼ëª… ì‚¬ìš©)
            kor_col = tag_mapping.get(eng_col, eng_col)
            converted_row[kor_col] = value
        converted_data.append(converted_row)
    
    return converted_data


def get_pims_data_with_batch_times(itemcode: str, batches_with_times: dict, proc_code: str, limit: int = 50, data_type: str = "basic") -> List[Dict[str, Any]]:
    """
    ë°°ì¹˜ë³„ ê°œë³„ ì‹œê°„ ì„¤ì •ìœ¼ë¡œ PIMS ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        itemcode: í’ˆëª© ì½”ë“œ
        batches_with_times: ë°°ì¹˜ë³„ ì‹œê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬ 
                           {"ë°°ì¹˜ë²ˆí˜¸": {"start": "ì‹œì‘ì‹œê°„", "end": "ì¢…ë£Œì‹œê°„"}}
        proc_code: ê³µì • ì½”ë“œ
        limit: ì¡°íšŒ ê±´ìˆ˜ ì œí•œ
        data_type: ë°ì´í„° íƒ€ì… ("basic" ë˜ëŠ” "l23")
    
    Returns:
        List[Dict[str, Any]]: ëª¨ë“  ë°°ì¹˜ì˜ ì¡°íšŒ ê²°ê³¼ë¥¼ ë³‘í•©í•œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    all_results = []
    
    for batch_no, time_range in batches_with_times.items():
        start_time = time_range.get('start') or ""
        end_time = time_range.get('end') or ""
        
        print(f"ë°°ì¹˜ {batch_no} ì¡°íšŒ: {start_time} ~ {end_time}")
        
        try:
            # ë°°ì¹˜ë³„ë¡œ ê°œë³„ ì¡°íšŒ
            if data_type == "basic":
                batch_results = get_pims_data_basic(itemcode, batch_no, proc_code, start_time, end_time, limit)
            else:  # l23
                batch_results = get_pims_data_l23(itemcode, batch_no, proc_code, start_time, end_time, limit)
            
            if batch_results:
                print(f"ë°°ì¹˜ {batch_no}: {len(batch_results)}ê±´ ì¡°íšŒë¨")
                all_results.extend(batch_results)
            else:
                print(f"ë°°ì¹˜ {batch_no}: ì¡°íšŒëœ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"ë°°ì¹˜ {batch_no} ì¡°íšŒ ì˜¤ë¥˜: {e}")
            continue
    
    print(f"ì „ì²´ ì¡°íšŒ ì™„ë£Œ: {len(all_results)}ê±´ (ë°°ì¹˜ {len(batches_with_times)}ê°œ)")
    return all_results


def search_product(itemcode: str, batch_no: str = "", proc_code: str = ""):
    """
    í’ˆëª© ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    UP_AI_SearchProduct í”„ë¡œì‹œì €ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        itemcode (str): í’ˆëª© ì½”ë“œ
        batch_no (str): ë°°ì¹˜ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)
        proc_code (str): ê³µì • ì½”ë“œ (ì„ íƒì‚¬í•­)
    
    Returns:
        list: ì¡°íšŒëœ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë°°ì¹˜/ê³µì • ëª©ë¡ìš©ì´ë¯€ë¡œ ì˜ë¬¸ ì»¬ëŸ¼ëª… ìœ ì§€, ê³µì •ì€ í•œê¸€ëª… ì¶”ê°€)
    """
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    conn_info = get_mssql_connection_dict()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°
    conn = pymssql.connect(**conn_info)
    cursor = conn.cursor(as_dict=True)  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°›ê¸°
    
    # SQL ì¿¼ë¦¬ ì‹¤í–‰ (ì¥ê³  ë°©ì‹ì²˜ëŸ¼)
    query = """
        DECLARE @return_value int;
        EXEC @return_value = [dbo].[UP_AI_SearchProduct] 
        @itemcode = %s, 
        @BatchNo = %s, 
        @ProcCode = %s;
    """
    cursor.execute(query, (itemcode, batch_no, proc_code))
    
    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    results = cursor.fetchall()
    
    # ì—°ê²° ë‹«ê¸°
    cursor.close()
    conn.close()
    
    # ê³µì •ëª… ë§¤í•‘ ë¡œë“œ ë° ê³µì • í•„í„°ë§/ë³€í™˜ (ê³µì •ì½”ë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ)
    if proc_code == "":  # ê³µì • ëª©ë¡ ì¡°íšŒì¸ ê²½ìš°
        process_mapping = load_process_mapping()
        results = filter_and_convert_processes(results, process_mapping)
    
    return results


def get_pims_data_basic(itemcode: str, batch_no: str, proc_code: str, start_time: str = "", end_time: str = "", limit: int = 50):
    """
    ê¸°ì¡´ê³ í˜•ì œ PIMS ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    Get_AIDATA í”„ë¡œì‹œì €ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        itemcode (str): í’ˆëª© ì½”ë“œ
        batch_no (str): ë°°ì¹˜ ë²ˆí˜¸
        proc_code (str): ê³µì • ì½”ë“œ
        start_time (str): ì‹œì‘ ì‹œê°„ (ì„ íƒì‚¬í•­)
        end_time (str): ì¢…ë£Œ ì‹œê°„ (ì„ íƒì‚¬í•­)
        limit (int): ì¡°íšŒ ê±´ìˆ˜ ì œí•œ (ê¸°ë³¸: 50ê±´, 0 ì´í•˜ë©´ ëª¨ë“  ë°ì´í„°)
    
    Returns:
        list: ì¡°íšŒëœ PIMS ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ limit ê±´, limit <= 0ì´ë©´ ëª¨ë“  ë°ì´í„°, ì»¬ëŸ¼ëª…ì€ í•œê¸€ë¡œ ë³€í™˜ë¨)
    """
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    conn_info = get_mssql_connection_dict()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°
    conn = pymssql.connect(**conn_info)
    cursor = conn.cursor(as_dict=True)  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°›ê¸°
    
    # SQL ì¿¼ë¦¬ ì‹¤í–‰
    query = """
        DECLARE @return_value int; 
        EXEC @return_value = [dbo].[Get_AIDATA] 
        @itemcode = %s, 
        @BatchNo = %s, 
        @ProcCode = %s;
    """
    cursor.execute(query, (itemcode, batch_no, proc_code))
    
    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    results = cursor.fetchall()
    
    # ì—°ê²° ë‹«ê¸°
    cursor.close()
    conn.close()
    
    # íƒœê·¸ ë§¤í•‘ ë¡œë“œ ë° ì»¬ëŸ¼ëª… ë³€í™˜
    tag_mapping = load_tag_mapping()
    converted_results = convert_columns_to_korean(results, tag_mapping)
    
    # ì„±ëŠ¥ ìµœì í™”: ì›¹ ì¡°íšŒ(limit > 0)ì™€ ë‹¤ìš´ë¡œë“œ(limit <= 0)ë¥¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
    if limit > 0:
        # ì›¹ ì¡°íšŒ: ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ì²˜ë¦¬ ìˆœì„œ ìµœì í™”
        if start_time and end_time:
            # ì‹œê°„ í•„í„°ë§ì´ ìˆìœ¼ë©´ ì •í™•ì„±ì„ ìœ„í•´ í•„í„°ë§ í›„ limit ì ìš©
            converted_results = filter_by_time_range(converted_results, start_time, end_time, tag_mapping)
            converted_results = converted_results[:limit]
        else:
            # ì‹œê°„ í•„í„°ë§ì´ ì—†ìœ¼ë©´ ë°”ë¡œ limit ì ìš© (ë§¤ìš° ë¹ ë¦„)
            converted_results = converted_results[:limit]
    else:
        # ë‹¤ìš´ë¡œë“œ: ì •í™•í•œ ë°ì´í„°ë¥¼ ìœ„í•´ ì‹œê°„ í•„í„°ë§ í›„ ëª¨ë“  ë°ì´í„°
        if start_time and end_time:
            converted_results = filter_by_time_range(converted_results, start_time, end_time, tag_mapping)
    
    return converted_results


def get_pims_data_l23(itemcode: str, batch_no: str, proc_code: str, start_time: str = "", end_time: str = "", limit: int = 50):
    """
    ìŠ¤ë§ˆíŠ¸ê³ í˜•ì œ PIMS ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
    Get_AIDATA_L23 í”„ë¡œì‹œì €ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        itemcode (str): í’ˆëª© ì½”ë“œ
        batch_no (str): ë°°ì¹˜ ë²ˆí˜¸ (ì—¬ëŸ¬ ê°œì¸ ê²½ìš° ì‰¼í‘œë¡œ êµ¬ë¶„)
        proc_code (str): ê³µì • ì½”ë“œ
        start_time (str): ì‹œì‘ ì‹œê°„ (ì„ íƒì‚¬í•­)
        end_time (str): ì¢…ë£Œ ì‹œê°„ (ì„ íƒì‚¬í•­)
        limit (int): ì¡°íšŒ ê±´ìˆ˜ ì œí•œ (ê¸°ë³¸: 50ê±´, 0 ì´í•˜ë©´ ëª¨ë“  ë°ì´í„°)
    
    Returns:
        list: ì¡°íšŒëœ PIMS ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ limit ê±´, limit <= 0ì´ë©´ ëª¨ë“  ë°ì´í„°, ì»¬ëŸ¼ëª…ì€ í•œê¸€ë¡œ ë³€í™˜ë¨)
    """
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    conn_info = get_mssql_connection_dict()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°
    conn = pymssql.connect(**conn_info)
    cursor = conn.cursor(as_dict=True)  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°›ê¸°
    
    # SQL ì¿¼ë¦¬ ì‹¤í–‰
    query = """
        DECLARE @return_value int; 
        EXEC @return_value = [dbo].[Get_AIDATA_L23] 
        @itemcode = %s, 
        @BatchNo = %s, 
        @ProcCode = %s;
    """
    cursor.execute(query, (itemcode, batch_no, proc_code))
    
    # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    results = cursor.fetchall()
    
    # ì—°ê²° ë‹«ê¸°
    cursor.close()
    conn.close()
    
    # íƒœê·¸ ë§¤í•‘ ë¡œë“œ ë° ì»¬ëŸ¼ëª… ë³€í™˜
    tag_mapping = load_tag_mapping()
    converted_results = convert_columns_to_korean(results, tag_mapping)
    
    # ì„±ëŠ¥ ìµœì í™”: ì›¹ ì¡°íšŒ(limit > 0)ì™€ ë‹¤ìš´ë¡œë“œ(limit <= 0)ë¥¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
    if limit > 0:
        # ì›¹ ì¡°íšŒ: ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ ì²˜ë¦¬ ìˆœì„œ ìµœì í™”
        if start_time and end_time:
            # ì‹œê°„ í•„í„°ë§ì´ ìˆìœ¼ë©´ ì •í™•ì„±ì„ ìœ„í•´ í•„í„°ë§ í›„ limit ì ìš©
            converted_results = filter_by_time_range(converted_results, start_time, end_time, tag_mapping)
            converted_results = converted_results[:limit]
        else:
            # ì‹œê°„ í•„í„°ë§ì´ ì—†ìœ¼ë©´ ë°”ë¡œ limit ì ìš© (ë§¤ìš° ë¹ ë¦„)
            converted_results = converted_results[:limit]
    else:
        # ë‹¤ìš´ë¡œë“œ: ì •í™•í•œ ë°ì´í„°ë¥¼ ìœ„í•´ ì‹œê°„ í•„í„°ë§ í›„ ëª¨ë“  ë°ì´í„°
        if start_time and end_time:
            converted_results = filter_by_time_range(converted_results, start_time, end_time, tag_mapping)
    
    return converted_results


def load_process_type_mapping() -> Dict[str, str]:
    """
    ê³µì •ê·¸ë£¹.csv íŒŒì¼ì„ ì½ì–´ì„œ ê³µì •ì½”ë“œ â†’ ê³µì •íƒ€ì… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜
    
    ì˜ˆ: {'AB0': 'ê³¼ë¦½', 'AH0': 'íƒ€ì •', 'AI0': 'ì½”íŒ…'}
    
    Returns:
        Dict[str, str]: {ê³µì •ì½”ë“œ: ê³µì •íƒ€ì…} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # CSV íŒŒì¼ ê²½ë¡œ (app í´ë” ì•ˆ)
        csv_path = os.path.join(os.path.dirname(__file__), '..', 'ê³µì •ê·¸ë£¹.csv')
        
        # CSV íŒŒì¼ ì½ê¸° (í•œê¸€ ì¸ì½”ë”©)
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ê³µì •ì½”ë“œ â†’ ê³µì •íƒ€ì…)
        process_type_mapping = dict(zip(df['ê³µì •ì½”ë“œ'].str.strip(), df['ê³µì •íƒ€ì…'].str.strip()))
        
        print(f"ğŸ“‹ ê³µì •íƒ€ì… ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(process_type_mapping)}ê°œ")
        return process_type_mapping
        
    except Exception as e:
        print(f"âŒ ê³µì •íƒ€ì… ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def load_process_variable_mapping() -> Dict[str, List[str]]:
    """
    ê³µì •ë³€ìˆ˜ë§¤í•‘.csv íŒŒì¼ì„ ì½ì–´ì„œ ê³µì •íƒ€ì… â†’ ë³€ìˆ˜ëª©ë¡ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜
    
    ì˜ˆ: {'ê³¼ë¦½': ['L11_1110_FBG5_AIR_F', ...], 'ë£¸ìƒíƒœ': ['L23_2526_REMS_T', ...]}
    
    Returns:
        Dict[str, List[str]]: {ê³µì •íƒ€ì…: [ë³€ìˆ˜ëª…ë“¤]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # CSV íŒŒì¼ ê²½ë¡œ (app í´ë” ì•ˆ)
        csv_path = os.path.join(os.path.dirname(__file__), '..', 'ê³µì •ë³€ìˆ˜ë§¤í•‘.csv')
        
        # CSV íŒŒì¼ ì½ê¸° (í•œê¸€ ì¸ì½”ë”©)
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        # ê³µì •íƒ€ì…ë³„ë¡œ ë³€ìˆ˜ë“¤ì„ ê·¸ë£¹í™”
        process_variable_mapping = {}
        for process_type in df['ê³µì •íƒ€ì…'].unique():
            # í•´ë‹¹ ê³µì •íƒ€ì…ì˜ ëª¨ë“  ë³€ìˆ˜ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì§‘
            variables = df[df['ê³µì •íƒ€ì…'] == process_type]['ë³€ìˆ˜ëª…(ì˜ë¬¸)'].str.strip().tolist()
            process_variable_mapping[process_type] = variables
        
        print(f"ğŸ“‹ ê³µì •ë³€ìˆ˜ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ: {len(process_variable_mapping)}ê°œ ê³µì •íƒ€ì…")
        
        # ê° ê³µì •íƒ€ì…ë³„ ë³€ìˆ˜ ê°œìˆ˜ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        for ptype, variables in process_variable_mapping.items():
            print(f"  - {ptype}: {len(variables)}ê°œ ë³€ìˆ˜")
            
        return process_variable_mapping
        
    except Exception as e:
        print(f"âŒ ê³µì •ë³€ìˆ˜ ë§¤í•‘ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def filter_data_by_process_type(data: List[Dict[str, Any]], proc_code: str) -> List[Dict[str, Any]]:
    """
    ì„ íƒëœ ê³µì •ì½”ë“œì— ë”°ë¼ ê´€ë ¨ ë³€ìˆ˜ë“¤ë§Œ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜
    
    ğŸ“Œ í•„í„°ë§ ê·œì¹™:
    1. ì„ íƒëœ ê³µì •ì˜ íƒ€ì…ì— í•´ë‹¹í•˜ëŠ” ë³€ìˆ˜ë“¤
    2. ë£¸ìƒíƒœ ë³€ìˆ˜ë“¤ (ëª¨ë“  ê³µì •ì—ì„œ í•­ìƒ í‘œì‹œ)
    3. ê¸°ë³¸ ì‹œìŠ¤í…œ ë³€ìˆ˜ë“¤ (ì‹œê°„, ë°°ì¹˜ë²ˆí˜¸ ë“±)
    
    Args:
        data: ì›ë³¸ PIMS ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜ëœ ìƒíƒœ)
        proc_code: ì„ íƒëœ ê³µì •ì½”ë“œ (ì˜ˆ: 'AB1', 'AH0')
    
    Returns:
        List[Dict[str, Any]]: í•„í„°ë§ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if not data:
        print("âš ï¸  í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return data
    
    print(f"ğŸ” ê³µì •ì½”ë“œ '{proc_code}'ì— ëŒ€í•œ ë°ì´í„° í•„í„°ë§ ì‹œì‘...")
    
    # 1. ë§¤í•‘ ì •ë³´ ë¡œë“œ
    process_type_mapping = load_process_type_mapping()       # ê³µì •ì½”ë“œ â†’ ê³µì •íƒ€ì…
    process_variable_mapping = load_process_variable_mapping()  # ê³µì •íƒ€ì… â†’ ë³€ìˆ˜ëª©ë¡
    tag_mapping = load_tag_mapping()  # ì˜ë¬¸ â†’ í•œê¸€ ë³€ìˆ˜ëª… ë§¤í•‘
    
    # 2. ì„ íƒëœ ê³µì •ì˜ íƒ€ì… í™•ì¸
    process_type = process_type_mapping.get(proc_code, "")
    
    if not process_type:
        print(f"âš ï¸  ê³µì •ì½”ë“œ '{proc_code}'ì˜ íƒ€ì…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë§ ì•ˆí•¨.")
        return data  # í•„í„°ë§ ì—†ì´ ì›ë³¸ ë°ì´í„° ë°˜í™˜
    
    print(f"âœ… ê³µì •ì½”ë“œ '{proc_code}' â†’ ê³µì •íƒ€ì… '{process_type}'")
    
    # 3. í‘œì‹œí•  ë³€ìˆ˜ë“¤ ìˆ˜ì§‘ (í—ˆìš©ëœ ë³€ìˆ˜ë“¤ì˜ ì§‘í•©) - ì˜ë¬¸ëª…ìœ¼ë¡œ ìˆ˜ì§‘ í›„ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜
    allowed_variables_eng = set()
    
    # 3-1. ì„ íƒëœ ê³µì •íƒ€ì…ì˜ ë³€ìˆ˜ë“¤ ì¶”ê°€
    if process_type in process_variable_mapping:
        type_variables = process_variable_mapping[process_type]
        allowed_variables_eng.update(type_variables)
        print(f"ğŸ“Š '{process_type}' ê³µì •ë³€ìˆ˜: {len(type_variables)}ê°œ ì¶”ê°€")
    
    # 3-2. ë£¸ìƒíƒœ ë³€ìˆ˜ë“¤ ì¶”ê°€ (ëª¨ë“  ê³µì •ì—ì„œ í‘œì‹œ)
    if "ë£¸ìƒíƒœ" in process_variable_mapping:
        room_variables = process_variable_mapping["ë£¸ìƒíƒœ"]
        allowed_variables_eng.update(room_variables)
        print(f"ğŸ  ë£¸ìƒíƒœ ë³€ìˆ˜: {len(room_variables)}ê°œ ì¶”ê°€")
    
    # 3-3. ê¸°ë³¸ ì‹œìŠ¤í…œ ë³€ìˆ˜ë“¤ ì¶”ê°€ (í•­ìƒ í‘œì‹œ) - ì˜ë¬¸ëª…
    basic_variables_eng = [
        "AUFNR",           # ì‘ì—…ë²ˆí˜¸
        "MATNR",           # í’ˆëª©ì½”ë“œ  
        "CHARG",           # ë°°ì¹˜ë²ˆí˜¸
        "ACT_START",       # ì‹œì‘ì‹œê°
        "ACT_FINISH",      # ì¢…ë£Œì‹œê°
        "VORNR",           # ì‘ì—…ìˆœì„œ
        "KTSCH",           # ê³µì •ì½”ë“œ
        "ACT_FINISH_TIMS", # ì´ì‹œê°„(ì´ˆ)
        "STATUS3",         # ìƒíƒœ(X=ì¢…ë£Œ)
        "KTEXT",           # ì„¤ë¹„ì •ë³´
        "ITIME"            # ì‹œê°„
    ]
    allowed_variables_eng.update(basic_variables_eng)
    print(f"âš™ï¸  ê¸°ë³¸ ì‹œìŠ¤í…œ ë³€ìˆ˜: {len(basic_variables_eng)}ê°œ ì¶”ê°€")
    
    # 3-4. ì˜ë¬¸ëª…ì„ í•œê¸€ëª…ìœ¼ë¡œ ë³€í™˜ (ë°ì´í„°ëŠ” ì´ë¯¸ í•œê¸€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜ëœ ìƒíƒœ)
    allowed_variables_kor = set()
    for eng_var in allowed_variables_eng:
        kor_var = tag_mapping.get(eng_var, eng_var)  # í•œê¸€ëª…ì´ ì—†ìœ¼ë©´ ì˜ë¬¸ëª… ê·¸ëŒ€ë¡œ
        allowed_variables_kor.add(kor_var)
    
    print(f"ğŸ¯ ì´ í—ˆìš©ëœ ë³€ìˆ˜: {len(allowed_variables_kor)}ê°œ (í•œê¸€ëª… ê¸°ì¤€)")
    
    # 4. ë°ì´í„° í•„í„°ë§ ì‹¤í–‰
    filtered_data = []
    original_column_count = len(data[0].keys()) if data else 0
    
    for row in data:
        # ìƒˆë¡œìš´ í–‰ ìƒì„± (í—ˆìš©ëœ ë³€ìˆ˜ë“¤ë§Œ í¬í•¨)
        filtered_row = {}
        for key, value in row.items():
            if key in allowed_variables_kor:
                filtered_row[key] = value
        
        filtered_data.append(filtered_row)
    
    # 5. í•„í„°ë§ ê²°ê³¼ ì¶œë ¥
    filtered_column_count = len(filtered_data[0].keys()) if filtered_data else 0
    print(f"âœ… í•„í„°ë§ ì™„ë£Œ: {original_column_count}ê°œ â†’ {filtered_column_count}ê°œ ì»¬ëŸ¼")
    print(f"ğŸ“ˆ ë°ì´í„° í–‰ ìˆ˜: {len(filtered_data)}ê±´")
    
    return filtered_data